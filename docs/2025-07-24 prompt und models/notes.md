# Prompt und Modelle

Also ich habe verschiedenes ausprobiert. Ich habe herausgefunden dass man ein YouTube Transkript relativ schnell und einfach runterladen kann. Dafür gibt es existierende Tools. Der erste Ansatz war das komplette Skript mit den Zeit stempeln Als zusätzlichen Kontext der KI mitzugeben. Das hat so überhaupt nicht funktioniert da man hier für bei meinem durchschnittlichen Beispiel Video schon mehr als 20.000 Tokens braucht. Es gibt auch Modelle die das schaffen und die auch lokal laufen, sehr spät habe ich dann aber rausgefunden dass das Modell stark verlangsamt. Umso mehr im System prompt steht umso langsamer wird alles. Deshalb habe ich dann ein Skript von der KI erstellen lassen um nur den Text aus dem Transkript zu extrahieren. Mit diesem Text als Kontext hab meine Beispielschnipsel bestehend aus zwei Sätze aber immer noch ungefähr 50 Sekunden gedauert um verbessert zu werden. Als nächsten Schritt habe ich dann der KI aufgetragen aus dem Transkript alle wichtigen Namen und technischen Begriffe zu extrahieren und aufzulisten. Außerdem das Video in 50 Wörtern zusammenfassen. Beides funktioniert sehr gut um spezielle Begriffe wie Obsidian als Notiz System ChatGPT vier als spezielle Version eines Modells ohne auch Eigennamen wie Dailymotion besser zu erkennen. Ich habe kurz auch probiert ohne diesen Kontext die gleichen Teile übersetzen zu lassen was trotzdem gut funktioniert hat, aber eben bei diesen Eigennamen nicht sehr gut. Hier sind wir dann bei circa 20 Sekunden pro Schnipsel. Meine Tests habe ich mit dem Web Interface OpenAI gemacht das automatisch auch alle bestehenden Nachrichten wieder dem Modell zur Verfügung stellt. Hier kann man noch das Gedächtnis sozusagen in Form dass jede Nachricht nur den System prompt als Kontext bekommt. Interessanterweise waren auch die kleineren Modelle schneller wie die größeren, ich hatte das verstanden dass es eigentlich andersrum sein sollte. Getestete Modelle:
* Llama3.1:8b
* mistral-nenom:12b
* gemma3:12b
* gemma3:4b

Temperatur war immer auf 0.3 gestellt.
Was auch besser funktioniert hat zu meinem prompt vorher war die Eingabe in `<notes>` Tags zu umschließen, damit die ki unterscheiden kann was eine Frage an sie ist und was Text den sie übersetzen soll. Die Extraktion vom Transkript in die wichtigsten Daten kann man gleich machen wenn in der UID YouTube rein eingetragen wurde und zum Sommer geschickt wird.